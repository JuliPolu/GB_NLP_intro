{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNkVIljUjfEl"
      },
      "source": [
        "## Задание"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IeNg--0Tjtsy"
      },
      "source": [
        "Разобраться с моделькой генерации текста, собрать самим или взять датасет с вебинара и обучить генератор текстов."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_Es19lUjygW"
      },
      "source": [
        "## Решение:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHGkWsVsE9qw"
      },
      "source": [
        "В качестве основы для генерации текста используем роман Л.Н.Толстого \"Анна Каренина\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-11T19:53:21.683563Z",
          "iopub.status.busy": "2022-09-11T19:53:21.683121Z",
          "iopub.status.idle": "2022-09-11T19:53:26.264043Z",
          "shell.execute_reply": "2022-09-11T19:53:26.263050Z",
          "shell.execute_reply.started": "2022-09-11T19:53:21.683474Z"
        },
        "id": "NJDQiovZe763",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-11T19:53:45.026745Z",
          "iopub.status.busy": "2022-09-11T19:53:45.026377Z",
          "iopub.status.idle": "2022-09-11T19:53:45.059417Z",
          "shell.execute_reply": "2022-09-11T19:53:45.058366Z",
          "shell.execute_reply.started": "2022-09-11T19:53:45.026712Z"
        },
        "id": "F4f2bs_mkr-C",
        "outputId": "f0431d8d-eec6-4b85-b481-6ecf45d2b556",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Длина текста: 1881028 символов.\n"
          ]
        }
      ],
      "source": [
        "path_to_file = '/content/Anna_Karenina.txt'\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='cp1251')\n",
        "print(f'Длина текста: {len(text)} символов.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-11T19:53:46.427338Z",
          "iopub.status.busy": "2022-09-11T19:53:46.426447Z",
          "iopub.status.idle": "2022-09-11T19:53:46.434916Z",
          "shell.execute_reply": "2022-09-11T19:53:46.433828Z",
          "shell.execute_reply.started": "2022-09-11T19:53:46.427301Z"
        },
        "id": "dhb38ThH99Vv",
        "outputId": "08868c21-d699-4bcd-8ef3-58b406f788f4",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Анна Каренина\r\n",
            "Лев Николаевич Толстой\r\n",
            "\r\n",
            "\r\n",
            "Библиотека всемирной литературы (Эксмо)\r\n",
            "«Анну Каренину» Толстой называл «романом широким и свободным». В основе этого определения пушкинский термин «свободн\n"
          ]
        }
      ],
      "source": [
        "print(text[:200])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-11T19:53:48.031519Z",
          "iopub.status.busy": "2022-09-11T19:53:48.030584Z",
          "iopub.status.idle": "2022-09-11T19:53:48.132973Z",
          "shell.execute_reply": "2022-09-11T19:53:48.131855Z",
          "shell.execute_reply.started": "2022-09-11T19:53:48.031469Z"
        },
        "id": "ctQ4OcJx-EFh",
        "outputId": "4f49d686-1cd9-4cbb-ea02-0dea5804e3b7",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "148 уникальных символов в тексте.\n"
          ]
        }
      ],
      "source": [
        "# Количество уникальных символов, которые будут составлять наш словарь\n",
        "\n",
        "vocab = sorted(set(text))\n",
        "print(f'{len(vocab)} уникальных символов в тексте.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-11T19:53:48.823098Z",
          "iopub.status.busy": "2022-09-11T19:53:48.822375Z",
          "iopub.status.idle": "2022-09-11T19:53:49.169863Z",
          "shell.execute_reply": "2022-09-11T19:53:49.168822Z",
          "shell.execute_reply.started": "2022-09-11T19:53:48.823061Z"
        },
        "id": "hQ8e8Ccl_N8L",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Создаем сопоставление между символами и их индексами \n",
        "# Преобразовываем текст из символьного в индексный вид\n",
        "\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "text_as_int = np.array([char2idx[c] for c in text])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-11T19:53:49.522711Z",
          "iopub.status.busy": "2022-09-11T19:53:49.522128Z",
          "iopub.status.idle": "2022-09-11T19:53:52.521999Z",
          "shell.execute_reply": "2022-09-11T19:53:52.520904Z",
          "shell.execute_reply.started": "2022-09-11T19:53:49.522674Z"
        },
        "id": "6AL-q-CGAJc1",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "seq_length = 100\n",
        "examples_per_epoch = len(text)//(seq_length+1)\n",
        "\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "\n",
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-11T19:53:52.525555Z",
          "iopub.status.busy": "2022-09-11T19:53:52.525242Z",
          "iopub.status.idle": "2022-09-11T19:53:52.600830Z",
          "shell.execute_reply": "2022-09-11T19:53:52.599829Z",
          "shell.execute_reply.started": "2022-09-11T19:53:52.525527Z"
        },
        "id": "G4PgOAILAz2L",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Сформируем датасет, выделяя предсказываемый текст\n",
        "\n",
        "def split_input_target(chunk):\n",
        "    input_text = chunk[:-1]\n",
        "    target_text = chunk[1:]\n",
        "    return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-11T19:53:52.603683Z",
          "iopub.status.busy": "2022-09-11T19:53:52.602912Z",
          "iopub.status.idle": "2022-09-11T19:53:52.615080Z",
          "shell.execute_reply": "2022-09-11T19:53:52.613870Z",
          "shell.execute_reply.started": "2022-09-11T19:53:52.603646Z"
        },
        "id": "FOWi0BdhA6Sr",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Перемешаем датасет и разделим его на батчи\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "EPOCHS = 20\n",
        "\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-11T19:53:52.618835Z",
          "iopub.status.busy": "2022-09-11T19:53:52.618433Z",
          "iopub.status.idle": "2022-09-11T19:53:52.623704Z",
          "shell.execute_reply": "2022-09-11T19:53:52.622349Z",
          "shell.execute_reply.started": "2022-09-11T19:53:52.618794Z"
        },
        "id": "yb0SDawiBApu",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Гиперпараметры необходимые в процессе обучения модели\n",
        "\n",
        "vocab_size = len(vocab)\n",
        "embedding_dim = 256\n",
        "rnn_units = 1024"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYlQb8A2uCcL"
      },
      "source": [
        "Создадим модель с помощью стэкинга LSTM блоков."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-11T19:54:12.452043Z",
          "iopub.status.busy": "2022-09-11T19:54:12.451048Z",
          "iopub.status.idle": "2022-09-11T19:54:12.460276Z",
          "shell.execute_reply": "2022-09-11T19:54:12.458901Z",
          "shell.execute_reply.started": "2022-09-11T19:54:12.452006Z"
        },
        "id": "B_783JL3lwqh",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                                  batch_input_shape=[batch_size, None]),\n",
        "                                 \n",
        "        tf.keras.layers.LSTM(rnn_units // 2,\n",
        "                            return_sequences=True,\n",
        "                            stateful=True,\n",
        "                            recurrent_initializer='glorot_uniform'),\n",
        "\n",
        "        tf.keras.layers.LSTM(rnn_units,\n",
        "                            return_sequences=True,\n",
        "                            stateful=True,\n",
        "                            recurrent_initializer='glorot_uniform'),\n",
        "\n",
        "         tf.keras.layers.LSTM(rnn_units * 2,\n",
        "                            return_sequences=True,\n",
        "                            stateful=True,\n",
        "                            recurrent_initializer='glorot_uniform'),\n",
        "        \n",
        "        tf.keras.layers.LSTM(rnn_units,\n",
        "                            return_sequences=True,\n",
        "                            stateful=True,\n",
        "                            recurrent_initializer='glorot_uniform'),\n",
        "                                   \n",
        "        tf.keras.layers.Dense(vocab_size)\n",
        "    ])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-11T19:54:13.619102Z",
          "iopub.status.busy": "2022-09-11T19:54:13.618624Z",
          "iopub.status.idle": "2022-09-11T19:54:15.568846Z",
          "shell.execute_reply": "2022-09-11T19:54:15.567527Z",
          "shell.execute_reply.started": "2022-09-11T19:54:13.619068Z"
        },
        "id": "E3hTiZ9KBGDT",
        "outputId": "ff286234-ff44-49e9-844d-0c4f2a11ed40",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (64, None, 256)           37888     \n",
            "                                                                 \n",
            " lstm (LSTM)                 (64, None, 512)           1574912   \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (64, None, 1024)          6295552   \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (64, None, 2048)          25174016  \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (64, None, 1024)          12587008  \n",
            "                                                                 \n",
            " dense (Dense)               (64, None, 148)           151700    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 45,821,076\n",
            "Trainable params: 45,821,076\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = build_model(\n",
        "    vocab_size=len(vocab),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units,\n",
        "    batch_size=BATCH_SIZE)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ed6ogzyT_T2n"
      },
      "source": [
        "Обучаем модель."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-11T19:54:19.639365Z",
          "iopub.status.busy": "2022-09-11T19:54:19.638986Z",
          "iopub.status.idle": "2022-09-11T19:54:19.666644Z",
          "shell.execute_reply": "2022-09-11T19:54:19.665757Z",
          "shell.execute_reply.started": "2022-09-11T19:54:19.639335Z"
        },
        "id": "3L_5aLJbBSFo",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def loss(labels, logits):\n",
        "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "    \n",
        "model.compile(optimizer='adam', loss=loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-11T19:54:20.430999Z",
          "iopub.status.busy": "2022-09-11T19:54:20.430415Z",
          "iopub.status.idle": "2022-09-11T19:54:23.429593Z",
          "shell.execute_reply": "2022-09-11T19:54:23.428197Z",
          "shell.execute_reply.started": "2022-09-11T19:54:20.430961Z"
        },
        "id": "87OP8uOZBbeb",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "!rm -rf ./training_checkpoints\n",
        "!mkdir ./training_checkpoints\n",
        "!ls ./training_checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-11T19:54:25.203424Z",
          "iopub.status.busy": "2022-09-11T19:54:25.203016Z",
          "iopub.status.idle": "2022-09-11T19:54:25.211556Z",
          "shell.execute_reply": "2022-09-11T19:54:25.209163Z",
          "shell.execute_reply.started": "2022-09-11T19:54:25.203387Z"
        },
        "id": "ErgLXLEuBfpn",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_freq=88*5,\n",
        "    save_weights_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-11T19:54:26.918617Z",
          "iopub.status.busy": "2022-09-11T19:54:26.918246Z",
          "iopub.status.idle": "2022-09-11T20:31:54.033051Z",
          "shell.execute_reply": "2022-09-11T20:31:54.032029Z",
          "shell.execute_reply.started": "2022-09-11T19:54:26.918586Z"
        },
        "id": "sDj1TYU_BuQR",
        "outputId": "583a2734-78a4-4d5e-e99e-6ced7a7eca8c",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "291/291 [==============================] - 192s 592ms/step - loss: 2.8452\n",
            "Epoch 2/20\n",
            "291/291 [==============================] - 179s 608ms/step - loss: 2.0129\n",
            "Epoch 3/20\n",
            "291/291 [==============================] - 177s 600ms/step - loss: 1.5824\n",
            "Epoch 4/20\n",
            "291/291 [==============================] - 178s 605ms/step - loss: 1.4233\n",
            "Epoch 5/20\n",
            "291/291 [==============================] - 184s 627ms/step - loss: 1.3382\n",
            "Epoch 6/20\n",
            "291/291 [==============================] - 176s 598ms/step - loss: 1.2779\n",
            "Epoch 7/20\n",
            "291/291 [==============================] - 185s 627ms/step - loss: 1.2273\n",
            "Epoch 8/20\n",
            "291/291 [==============================] - 189s 640ms/step - loss: 1.1816\n",
            "Epoch 9/20\n",
            "291/291 [==============================] - 177s 603ms/step - loss: 1.1371\n",
            "Epoch 10/20\n",
            "291/291 [==============================] - 184s 627ms/step - loss: 1.0926\n",
            "Epoch 11/20\n",
            "291/291 [==============================] - 179s 609ms/step - loss: 1.0448\n",
            "Epoch 12/20\n",
            "291/291 [==============================] - 178s 603ms/step - loss: 0.9961\n",
            "Epoch 13/20\n",
            "291/291 [==============================] - 184s 627ms/step - loss: 0.9445\n",
            "Epoch 14/20\n",
            "291/291 [==============================] - 184s 627ms/step - loss: 0.8891\n",
            "Epoch 15/20\n",
            "291/291 [==============================] - 177s 603ms/step - loss: 0.8318\n",
            "Epoch 16/20\n",
            "291/291 [==============================] - 183s 624ms/step - loss: 0.7734\n",
            "Epoch 17/20\n",
            "291/291 [==============================] - 184s 625ms/step - loss: 0.7153\n",
            "Epoch 18/20\n",
            "291/291 [==============================] - 177s 603ms/step - loss: 0.6592\n",
            "Epoch 19/20\n",
            "291/291 [==============================] - 185s 627ms/step - loss: 0.6081\n",
            "Epoch 20/20\n",
            "291/291 [==============================] - 179s 608ms/step - loss: 0.5609\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-11T20:37:32.071569Z",
          "iopub.status.busy": "2022-09-11T20:37:32.071192Z",
          "iopub.status.idle": "2022-09-11T20:37:32.972286Z",
          "shell.execute_reply": "2022-09-11T20:37:32.971278Z",
          "shell.execute_reply.started": "2022-09-11T20:37:32.071539Z"
        },
        "id": "ifHG6PQ-n2d-",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "model.build(tf.TensorShape([1, None]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpyRC8bJ-Lvr"
      },
      "source": [
        "Воспользуемся функцией с лекции для предсказания текста."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-11T20:44:55.095102Z",
          "iopub.status.busy": "2022-09-11T20:44:55.094714Z",
          "iopub.status.idle": "2022-09-11T20:44:55.103910Z",
          "shell.execute_reply": "2022-09-11T20:44:55.102696Z",
          "shell.execute_reply.started": "2022-09-11T20:44:55.095070Z"
        },
        "id": "Vq5suJbMBvkI",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def generate_text(model, start_string):\n",
        "    # Количество генерируемых символов\n",
        "    num_generate = 700\n",
        "\n",
        "    input_eval = [char2idx[s] for s in start_string]\n",
        "    input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "    text_generated = []\n",
        "\n",
        "    temperature = 0.8\n",
        "\n",
        "    model.reset_states()\n",
        "    for i in range(num_generate):\n",
        "        predictions = model(input_eval)\n",
        "        predictions = tf.squeeze(predictions, 0)\n",
        "        predictions = predictions / temperature\n",
        "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
        "\n",
        "        input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "        text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "    return (start_string + ''.join(text_generated))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZC8Tuzv-Qg4"
      },
      "source": [
        "Сгенерируем текст."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-11T20:44:56.304274Z",
          "iopub.status.busy": "2022-09-11T20:44:56.303209Z",
          "iopub.status.idle": "2022-09-11T20:45:05.112347Z",
          "shell.execute_reply": "2022-09-11T20:45:05.111325Z",
          "shell.execute_reply.started": "2022-09-11T20:44:56.304228Z"
        },
        "id": "XzC8OPbdEfS-",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1ba62c7-fe17-4997-f989-8f276df49215"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Послышались шаги и мужской голос, на ходу на лестницу; но он тотчас же принял участие в общей замешание и от этого напряжения.\r\n",
            "\r\n",
            "– Да, это Алексей, – сказала она.\r\n",
            "\r\n",
            "– Пожалуй, и некогда профессором вы убеждены, – проговорил ей Матрен Федор, и ни на минуту, по выражению лица отца и до действий ездили все мужчины в одно впечатление разговорами молодых и стариков, и манилы большое умственное развитие. Он уже был не соглашался с этим, Степан Аркадьич не нашел на нее. «Я изменяю своему положению посмотреть на него. «Я знаю, что в можно, как наши откашли!» (62, 214).\r\n",
            "\r\n",
            "Переход от «Колпа! «Бог» он придет? – невольно красно обещает.\r\n",
            "\r\n",
            "– Нет, молодцом. Только бы тут. Теперь идите, ми. Вот у тебя красивой женщиной (франц.).\r\n",
            "\r\n",
            "\r\n",
            "\n"
          ]
        }
      ],
      "source": [
        "start_string = \"Послышались шаги и мужской голос,\"\n",
        "text_ = generate_text(model, start_string=start_string)\n",
        "print(text_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LsN5NqzuCcM"
      },
      "source": [
        "видим значительное снижение лосса. Текст генерируется, похож на настоящий, но если вглядеться, смысл оставляет желать лучшего."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gCqSl7Ahu-9A"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
