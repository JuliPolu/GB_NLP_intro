{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "704ba186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "from pymorphy2 import MorphAnalyzer\n",
    "from stop_words import get_stop_words\n",
    "import string\n",
    "import annoy\n",
    "from gensim.models import Word2Vec, FastText\n",
    "\n",
    "import os\n",
    "from telegram.ext  import Updater, CommandHandler, MessageHandler, Filters, CallbackContext\n",
    "from telegram import Update\n",
    "\n",
    "import re\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c2dbd042",
   "metadata": {},
   "source": [
    "### Создаем режим болталки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6cfefa6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем функции препроцессинга текста\n",
    "\n",
    "morpher = MorphAnalyzer()\n",
    "sw = set(get_stop_words(\"ru\"))\n",
    "exclude = set(string.punctuation)\n",
    "\n",
    "def remove_numbers(text):\n",
    "    return re.sub(r'\\d+', '', text)\n",
    "\n",
    "def remove_short_words(text):\n",
    "    return ' '.join([w for w in text.split() if len(w)>2])\n",
    "\n",
    "def remove_html_tags(text):\n",
    "    return re.sub(r'<.*?>', '', text)\n",
    "\n",
    "def remove_urls(text):\n",
    "    return re.sub(r'http\\S+|www.\\S+', '', text)\n",
    "\n",
    "def remove_extra_spaces(text):\n",
    "    return re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "def remove_non_alpha(text):\n",
    "    return re.sub(r'\\W+', ' ', text)\n",
    "\n",
    "def remove_repeated_characters(text):\n",
    "    return re.sub(r'(.)\\1+', r'\\1', text)\n",
    "\n",
    "def preprocess_txt(line):\n",
    "    line = remove_numbers(line)\n",
    "    line = remove_short_words(line)\n",
    "    line = remove_html_tags(line)\n",
    "    line = remove_urls(line)\n",
    "    line = remove_extra_spaces(line)\n",
    "    line = remove_emoji(line)\n",
    "    line = remove_non_alpha(line)\n",
    "    line = remove_repeated_characters(line)\n",
    "\n",
    "    spls = \"\".join(i for i in line.strip() if i not in exclude).split()\n",
    "    spls = [morpher.parse(i.lower())[0].normal_form for i in spls]\n",
    "    spls = [i for i in spls if i not in sw and i != \"\"]\n",
    "\n",
    "    return spls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf0aa57",
   "metadata": {},
   "source": [
    "Процесс обработки материалов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d11ab55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1012340d3318480abbeb184926bfe017",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# assert False\n",
    "\n",
    "#Small preprocess of the answers\n",
    "\n",
    "question = None\n",
    "written = False\n",
    "\n",
    "with open(\"../Less_3_word2vec/prepared_answers.txt\", \"w\") as fout:\n",
    "    with open(\"../Less_3_word2vec/Otvety.txt\", \"r\") as fin:\n",
    "        for line in tqdm(fin):\n",
    "            if line.startswith(\"---\"):\n",
    "                written = False\n",
    "                continue\n",
    "            if not written and question is not None:\n",
    "                fout.write(question.replace(\"\\t\", \" \").strip() + \"\\t\" + line.replace(\"\\t\", \" \"))\n",
    "                written = True\n",
    "                question = None\n",
    "                continue\n",
    "            if not written:\n",
    "                question = line.strip()\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7284b2d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j2/7fhv7lr576j7qyw_1c_4v7rr0000gn/T/ipykernel_57931/413239483.py:10: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for line in tqdm_notebook(fin):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ce233ce8236457e8f7ab98339aa8b34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "assert True\n",
    "\n",
    "# Preprocess for models fitting\n",
    "\n",
    "sentences = []\n",
    "\n",
    "c = 0\n",
    "\n",
    "with open(\"../Less_3_word2vec/Otvety.txt\", \"r\") as fin:\n",
    "    for line in tqdm_notebook(fin):\n",
    "        spls = preprocess_txt(line)\n",
    "        sentences.append(spls)\n",
    "        c += 1\n",
    "        if c > 500000:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2d8e77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [i for i in sentences if len(i) > 2]\n",
    "modelFT = FastText(sentences=sentences, size=100, min_count=1, window=5)\n",
    "modelFT.save(\"ft_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2bde130d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j2/7fhv7lr576j7qyw_1c_4v7rr0000gn/T/ipykernel_57931/1360323859.py:8: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for line in tqdm_notebook(f):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7878d953c3d5481aa9d88af4e1e47dc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelFT = FastText.load(\"ft_model\")\n",
    "ft_index = annoy.AnnoyIndex(100 ,'angular')\n",
    "\n",
    "index_map = {}\n",
    "counter = 0\n",
    "\n",
    "with open(\"../Less_3_word2vec/prepared_answers.txt\", \"r\") as f:\n",
    "    for line in tqdm_notebook(f):\n",
    "        n_ft = 0\n",
    "        spls = line.split(\"\\t\")\n",
    "        index_map[counter] = spls[1]\n",
    "        question = preprocess_txt(spls[0])\n",
    "        vector_ft = np.zeros(100)\n",
    "        for word in question:\n",
    "            if word in modelFT.wv:\n",
    "                vector_ft += modelFT.wv[word]\n",
    "                n_ft += 1\n",
    "        if n_ft > 0:\n",
    "            vector_ft = vector_ft / n_ft\n",
    "        ft_index.add_item(counter, vector_ft)\n",
    "            \n",
    "        counter += 1\n",
    "\n",
    "        if counter > 500000:\n",
    "            break\n",
    "\n",
    "ft_index.build(10)\n",
    "ft_index.save('speaker.ann')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f082590f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_index = annoy.AnnoyIndex(100, 'angular')\n",
    "ft_index.load('speaker.ann') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e560ef57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[503, 3359]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_index.get_nns_by_vector(np.zeros(100), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33909b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_txt(txt, idfs, midf):\n",
    "    n_ft = 0\n",
    "    vector_ft = np.zeros(100)\n",
    "    for word in txt:\n",
    "        if word in modelFT.wv:\n",
    "            vector_ft += modelFT.wv[word] * 1 # idfs.get(word, midf)\n",
    "            n_ft += 1 # idfs.get(word, midf)\n",
    "    return vector_ft / n_ft"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "77c1fa18",
   "metadata": {},
   "source": [
    "### Создаем режим перевода текста с английского на русский"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9424a593",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aleksandrkrylov/anaconda3/envs/GB_NLP_env/lib/python3.9/site-packages/transformers/models/marian/tokenization_marian.py:194: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54214b1db4f545509c1238ceff4d31cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/307M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b177a561054d4c20b8d6ca8a58e82e18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "model_name = \"Helsinki-NLP/opus-mt-en-ru\"\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Load the model\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6145887b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_english_to_russian(text):\n",
    "    # Encode the text\n",
    "    inputs = tokenizer.encode(text, return_tensors=\"pt\")\n",
    "\n",
    "    # Generate the translated text\n",
    "    outputs = model.generate(inputs, max_length=40, num_beams=4, early_stopping=True)\n",
    "\n",
    "    # Decode the outputs into a readable string\n",
    "    translated_text = tokenizer.decode(outputs[0])\n",
    "\n",
    "    return translated_text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d62d3749",
   "metadata": {},
   "source": [
    "### Создаем режим прогноза погоды"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa2d2f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для запроса прогноза погоды\n",
    "\n",
    "import requests \n",
    "import json\n",
    "\n",
    "key = '9ead4b09f8ab46fb9ce105955220407' # Токен https://www.weatherapi.com/\n",
    "\n",
    "def get_weather_forecast(city):\n",
    "    url = f'http://api.weatherapi.com/v1/current.json?key={key}&q={city}&lang=ru'\n",
    "    requests.get(url)\n",
    "    response = requests.get(url)\n",
    "    json_data = json.loads(response.text)\n",
    "\n",
    "    city = json_data['location']['name']\n",
    "    time = json_data['location']['localtime'].split(' ')[1]\n",
    "    temp = json_data['current']['temp_c']\n",
    "    temp_fl = json_data['current']['feelslike_c']\n",
    "    condition = json_data['current']['condition']['text']\n",
    "    wind = json_data['current']['wind_mph']\n",
    "    uv = json_data['current']['uv']\n",
    "\n",
    "    msg = f'В городе {city} сейчас {time}. О погоде: {condition}, температура {temp} градусов, ощущается как {temp_fl} градусов, скорость ветра {wind} м/ч, уровень ультрафиолета {uv}'\n",
    "\n",
    "    return msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "968c3ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download ru_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b5243848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определение города\n",
    "\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"ru_core_news_sm\")\n",
    "\n",
    "def recognize_location(text): \n",
    "    locs = []\n",
    "    doc = nlp(text)\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == 'LOC':\n",
    "            locs.append(ent.text)\n",
    "    locs = [morpher.parse(i.lower())[0].normal_form for i in locs]\n",
    "    return locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1803c5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Погода в запрашиваемом городе\n",
    "\n",
    "def forecast(text):\n",
    "    city = recognize_location(text)\n",
    "    try:\n",
    "        forecast = get_weather_forecast(city)\n",
    "    except:\n",
    "        forecast = \"Не понятен запрос\"\n",
    "    \n",
    "    return forecast"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e2a43ccb",
   "metadata": {},
   "source": [
    "### Процедура определения типа запроса "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e62a5300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверяем язык текста\n",
    "\n",
    "import re \n",
    "\n",
    "def english_check(text):\n",
    "    return bool(re.search(r'[a-zA-Z]', text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "08c7cff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Регулярное выражение для определения запроса о погоде\n",
    "weather_pattern = re.compile(r'\\b(погод[ауеы]|солнечн[аоеымй]|осадк[аиуеы]|дожд[аиуеымй]|снег[ауеым]|ливн[аеуиы]|зонт[ауеым])\\b', re.IGNORECASE)\n",
    "\n",
    "# Регулярное выражение для определения запроса на перевод\n",
    "translation_pattern = re.compile(r'\\b(перевод[ауеымч]|английск[ауеымий])\\b', re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6b887258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для проверки есть ли совпадение со списком ключевых слов\n",
    "\n",
    "def pattern_search(text, pattern):\n",
    "    for word in text:\n",
    "        if pattern.search(str(text)):\n",
    "            return True\n",
    "            break\n",
    "    return False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d65452c9",
   "metadata": {},
   "source": [
    "### Работа самого бота"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d9bb1849",
   "metadata": {},
   "outputs": [],
   "source": [
    "updater = Updater(token='YOUR_TOKEN') # Токен API к Telegram\n",
    "dispatcher = updater.dispatcher\n",
    "\n",
    "def startCommand(update: Update, context: CallbackContext):\n",
    "    update.message.reply_text('Доброго времени суток!')\n",
    "# Определеляем тип запроса пользования и ответа на него\n",
    "\n",
    "def textMessage(update: Update, context: CallbackContext):\n",
    "    input_txt = preprocess_txt(update.message.text)\n",
    "    \n",
    "    # Перевод \n",
    "    if english_check(update.message.text) == True:\n",
    "        update.message.reply_text(translate_english_to_russian(update.message.text))\n",
    "    elif pattern_search(input_txt, translation_pattern) == True:\n",
    "        update.message.reply_text(\"Какое предложение вам перевести?\") \n",
    "        \n",
    "    # Прогноз погоды    \n",
    "    elif pattern_search(input_txt, weather_pattern) == True:        \n",
    "        update.message.reply_text(forecast(update.message.text))\n",
    "            \n",
    "    # Болталка\n",
    "    else: \n",
    "        vect_ft = embed_txt(input_txt, {}, 1)\n",
    "        ft_index_val, distances = ft_index.get_nns_by_vector(vect_ft, 1, include_distances=True)\n",
    "        if distances[0] > 0.35:\n",
    "            print(distances[0])\n",
    "            update.message.reply_text(\"Не понимаю тебя\")\n",
    "        else:\n",
    "            update.message.reply_text(index_map[ft_index_val[0]])\n",
    "            \n",
    "    return\n",
    "\n",
    "\n",
    "start_command_handler = CommandHandler('start', startCommand)\n",
    "text_message_handler = MessageHandler(Filters.text, textMessage)\n",
    "dispatcher.add_handler(start_command_handler)\n",
    "dispatcher.add_handler(text_message_handler)\n",
    "updater.start_polling(clean=True)\n",
    "updater.idle()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
